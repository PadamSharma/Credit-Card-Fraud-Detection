{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Exploring the dataset","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport matplotlib.patches as mpatches\n\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import precision_score, average_precision_score, recall_score, f1_score,\\\nroc_auc_score, roc_curve, accuracy_score, classification_report, precision_recall_curve\n\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n\nfrom collections import Counter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-21T20:55:19.187198Z","iopub.execute_input":"2022-08-21T20:55:19.187651Z","iopub.status.idle":"2022-08-21T20:55:19.198340Z","shell.execute_reply.started":"2022-08-21T20:55:19.187618Z","shell.execute_reply":"2022-08-21T20:55:19.197281Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"full_df = pd.read_csv('../input/creditcardfraud/creditcard.csv')","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:28.339640Z","iopub.execute_input":"2022-08-21T20:22:28.340050Z","iopub.status.idle":"2022-08-21T20:22:33.569461Z","shell.execute_reply.started":"2022-08-21T20:22:28.340015Z","shell.execute_reply":"2022-08-21T20:22:33.568176Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"full_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:33.570796Z","iopub.execute_input":"2022-08-21T20:22:33.571148Z","iopub.status.idle":"2022-08-21T20:22:33.621886Z","shell.execute_reply.started":"2022-08-21T20:22:33.571115Z","shell.execute_reply":"2022-08-21T20:22:33.620757Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"\n#### There are no null values in any column\n\n#### All columns are encrypted and no logical sense could be made out of them, so resorting to statistical analysis to get forward in preprocessing this data\n\n","metadata":{}},{"cell_type":"code","source":"full_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:33.624346Z","iopub.execute_input":"2022-08-21T20:22:33.624968Z","iopub.status.idle":"2022-08-21T20:22:33.661911Z","shell.execute_reply.started":"2022-08-21T20:22:33.624933Z","shell.execute_reply":"2022-08-21T20:22:33.660834Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"full_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:33.663181Z","iopub.execute_input":"2022-08-21T20:22:33.663544Z","iopub.status.idle":"2022-08-21T20:22:34.157970Z","shell.execute_reply.started":"2022-08-21T20:22:33.663504Z","shell.execute_reply":"2022-08-21T20:22:34.157127Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Plotting Class, Time and Amount columns to get sense of their distribution","metadata":{}},{"cell_type":"markdown","source":"#### 1. Countplot for Class/Target column","metadata":{}},{"cell_type":"code","source":"print('Fraud datapoints = ', round(sum(full_df['Class'])/len(full_df)*100, 2),'% of Total datapoints, hence HIGHLY IMBALANCED')","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:34.159034Z","iopub.execute_input":"2022-08-21T20:22:34.160033Z","iopub.status.idle":"2022-08-21T20:22:34.189427Z","shell.execute_reply.started":"2022-08-21T20:22:34.159979Z","shell.execute_reply":"2022-08-21T20:22:34.188122Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,5))\nax = sns.countplot(x = full_df['Class'], data = full_df)\nax.set_xticklabels(['Non-Fraud', 'Fraud'])\nax.set_title('Distibution of Non-Fraud and Fraud instances')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:34.190910Z","iopub.execute_input":"2022-08-21T20:22:34.191294Z","iopub.status.idle":"2022-08-21T20:22:34.560880Z","shell.execute_reply.started":"2022-08-21T20:22:34.191245Z","shell.execute_reply":"2022-08-21T20:22:34.559697Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"#### 2. Fraud Amount vs Time","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(18,7))\nax = sns.scatterplot(x=full_df['Time'], y=full_df['Class']*full_df['Amount'])\nax.set(ylabel = 'Fraudulent Amount')","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:34.562691Z","iopub.execute_input":"2022-08-21T20:22:34.563149Z","iopub.status.idle":"2022-08-21T20:22:35.311549Z","shell.execute_reply.started":"2022-08-21T20:22:34.563105Z","shell.execute_reply":"2022-08-21T20:22:35.310460Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# 2. Scaling the dataset\n\nAs most of the columns are already scaled with mean ~ 0 and std ~ 1, the only columns remaining to scale are time and amount.\n\nUsing Robust Scaler to scale these columns as it is less prone to outliers as compared to Standard Scaler","metadata":{}},{"cell_type":"code","source":"rob_scaler = RobustScaler()\n\nfull_df['Scaled Amount'] = rob_scaler.fit_transform(full_df['Amount'].values.reshape(-1,1))\nfull_df['Scaled Time'] = rob_scaler.fit_transform(full_df['Time'].values.reshape(-1,1))\n\nfull_df.drop(['Time','Amount'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:35.312919Z","iopub.execute_input":"2022-08-21T20:22:35.313320Z","iopub.status.idle":"2022-08-21T20:22:35.421279Z","shell.execute_reply.started":"2022-08-21T20:22:35.313291Z","shell.execute_reply":"2022-08-21T20:22:35.420194Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# 3. Splitting the data into Train and Test","metadata":{}},{"cell_type":"code","source":"X = full_df.drop('Class', axis=1)\ny = full_df['Class']\n\nsss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n\nfor train_index, test_index in sss.split(X, y):\n    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n\n\n# Turn into an array\noriginal_Xtrain = original_Xtrain.values\noriginal_Xtest = original_Xtest.values\noriginal_ytrain = original_ytrain.values\noriginal_ytest = original_ytest.values\n\n# See if both the train and test label distribution are similarly distributed\ntrain_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\ntest_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n\nprint('Label Distributions: \\n')\nprint(train_counts_label/ len(original_ytrain))\nprint(test_counts_label/ len(original_ytest))","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:35.426175Z","iopub.execute_input":"2022-08-21T20:22:35.426660Z","iopub.status.idle":"2022-08-21T20:22:35.747567Z","shell.execute_reply.started":"2022-08-21T20:22:35.426622Z","shell.execute_reply":"2022-08-21T20:22:35.746289Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# 4. Performing Random Undersampling","metadata":{}},{"cell_type":"code","source":"suffled_df = full_df.sample(frac=1)\n\nfraud_df = suffled_df.loc[suffled_df['Class'] == 1]\nnon_fraud_df = suffled_df.loc[suffled_df['Class'] == 0][:492]\n\nnormal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n\nnew_df = normal_distributed_df.sample(frac=1, random_state=42)\n\nnew_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:35.749059Z","iopub.execute_input":"2022-08-21T20:22:35.749895Z","iopub.status.idle":"2022-08-21T20:22:35.915870Z","shell.execute_reply.started":"2022-08-21T20:22:35.749850Z","shell.execute_reply":"2022-08-21T20:22:35.914793Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print('Distribution of the Classes in the subsample dataset')\nprint(new_df['Class'].value_counts()/len(new_df))\n\nsns.countplot(x=new_df['Class'], data=new_df)\nplt.title('Equally Distributed Classes', fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:35.918289Z","iopub.execute_input":"2022-08-21T20:22:35.919139Z","iopub.status.idle":"2022-08-21T20:22:36.095631Z","shell.execute_reply.started":"2022-08-21T20:22:35.919103Z","shell.execute_reply":"2022-08-21T20:22:36.094339Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Exploring the Undersampled Data","metadata":{}},{"cell_type":"markdown","source":"## Correlation Matrices\n#### 1. Original Data","metadata":{}},{"cell_type":"code","source":"ax1 = plt.figure(figsize=(30,15))\n\n# Entire DataFrame\ncorr = full_df.corr()\nsns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':10}, annot=True)\nplt.title(\"Imbalanced Correlation Matrix of Imbalanced Original Data\", fontsize=14)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:36.097393Z","iopub.execute_input":"2022-08-21T20:22:36.098218Z","iopub.status.idle":"2022-08-21T20:22:41.335408Z","shell.execute_reply.started":"2022-08-21T20:22:36.098161Z","shell.execute_reply":"2022-08-21T20:22:41.334430Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"#### 2. Undersampled Data","metadata":{}},{"cell_type":"code","source":"ax2 = plt.figure(figsize=(30,15))\n\n# Entire DataFrame\ncorr = new_df.corr()\nsns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':10}, annot=True)\nplt.title(\"Balanced Correlation Matrix of Undersampled Data\", fontsize=14)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:41.336676Z","iopub.execute_input":"2022-08-21T20:22:41.337173Z","iopub.status.idle":"2022-08-21T20:22:45.396767Z","shell.execute_reply.started":"2022-08-21T20:22:41.337141Z","shell.execute_reply":"2022-08-21T20:22:45.395595Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(ncols=3, nrows=2, figsize=(20,10))\n\n# Negative Correlations with our Class (The lower our feature value the more likely it will be a fraud transaction)\nsns.boxplot(x=\"Class\", y=\"V9\", data=new_df, ax=axes[0][0])\naxes[0][0].set_title('V9 vs Class Negative Correlation')\n\nsns.boxplot(x=\"Class\", y=\"V10\", data=new_df, ax=axes[0][1])\naxes[0][1].set_title('V10 vs Class Negative Correlation')\n\nsns.boxplot(x=\"Class\", y=\"V12\", data=new_df,  ax=axes[0][2])\naxes[0][2].set_title('V12 vs Class Negative Correlation')\n\nsns.boxplot(x=\"Class\", y=\"V14\", data=new_df, ax=axes[1][0])\naxes[1][0].set_title('V14 vs Class Negative Correlation')\n\nsns.boxplot(x=\"Class\", y=\"V16\", data=new_df, ax=axes[1][1])\naxes[1][1].set_title('V14 vs Class Negative Correlation')\n\nsns.boxplot(x=\"Class\", y=\"V17\", data=new_df, ax=axes[1][2])\naxes[1][2].set_title('V17 vs Class Negative Correlation')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:45.398137Z","iopub.execute_input":"2022-08-21T20:22:45.398499Z","iopub.status.idle":"2022-08-21T20:22:46.083276Z","shell.execute_reply.started":"2022-08-21T20:22:45.398467Z","shell.execute_reply":"2022-08-21T20:22:46.082210Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(ncols=3, figsize=(20,4))\n\n# Negative Correlations with our Class (The lower our feature value the more likely it will be a fraud transaction)\nsns.boxplot(x=\"Class\", y=\"V2\", data=new_df, ax=axes[0])\naxes[0].set_title('V2 vs Class Positive Correlation')\n\nsns.boxplot(x=\"Class\", y=\"V4\", data=new_df, ax=axes[1])\naxes[1].set_title('V4 vs Class Positive Correlation')\n\nsns.boxplot(x=\"Class\", y=\"V11\", data=new_df,  ax=axes[2])\naxes[2].set_title('V11 vs Class Positive Correlation')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:46.084743Z","iopub.execute_input":"2022-08-21T20:22:46.085180Z","iopub.status.idle":"2022-08-21T20:22:46.457891Z","shell.execute_reply.started":"2022-08-21T20:22:46.085139Z","shell.execute_reply":"2022-08-21T20:22:46.456799Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"#### 3. Removing Outliers","metadata":{}},{"cell_type":"markdown","source":"These columns have positive correlations with the target class along with corr. value : \n\nV2  -> +0.5  \nV4  -> +0.73 (max positive corr.)  \nV11 -> +0.68  \n\nThese columns have positive correlations with the target class along with corr. value : \n\nV9  -> -0.55  \nV10 -> -0.63  \nV12 -> -0.68  \nV14 -> -0.75 (max negative corr.)  \nV16 -> -0.59  \nV17 -> -0.56  ","metadata":{}},{"cell_type":"code","source":"def remove_outliers(colname, threshold, new_df):\n    print('\\x1b[5;30;42m', colname, '\\x1b[0m')\n    vx_fraud = new_df[colname].loc[new_df['Class'] == 1].values\n    q25, q75 = np.percentile(vx_fraud, 25), np.percentile(vx_fraud, 75)\n    vx_iqr = q75 - q25\n\n    vx_cut_off = vx_iqr * threshold\n    vx_lower, vx_upper = q25 - vx_cut_off, q75 + vx_cut_off\n    \n    print(colname,'Lower: ',vx_lower)\n    print(colname,'Upper: ',vx_upper)\n\n    outliers = [x for x in vx_fraud if x < vx_lower or x > vx_upper]\n    print(colname,'Outliers: ',outliers)\n    print(colname,'Outliers for Fraud Cases: ',len(outliers))\n    new_df = new_df.drop(new_df[(new_df[colname] > vx_upper) | (new_df[colname] < vx_lower)].index)\n    print('Number of Instances after outliers removal: ',len(new_df))\n    print()\n    return new_df","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:46.459268Z","iopub.execute_input":"2022-08-21T20:22:46.460250Z","iopub.status.idle":"2022-08-21T20:22:46.468939Z","shell.execute_reply.started":"2022-08-21T20:22:46.460217Z","shell.execute_reply":"2022-08-21T20:22:46.467673Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print('Outlier removal from :')\npos_corr_cols = ['V2', 'V4', 'V11']\nneg_corr_cols = ['V9', 'V10', 'V12', 'V14', 'V16', 'V17']\n\nprint('\\x1b[5;30;41m', 'POSITIVE Corr. cols', '\\x1b[0m')\nfor cols in pos_corr_cols:\n    new_df = remove_outliers(cols, 1.5, new_df)\n\nprint('\\x1b[5;30;41m', 'NEGATIVE Corr. cols', '\\x1b[0m')\nfor cols in neg_corr_cols:\n    new_df = remove_outliers(cols, 1.5, new_df)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:46.470390Z","iopub.execute_input":"2022-08-21T20:22:46.470730Z","iopub.status.idle":"2022-08-21T20:22:46.506247Z","shell.execute_reply.started":"2022-08-21T20:22:46.470700Z","shell.execute_reply":"2022-08-21T20:22:46.505099Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing Data and Performing Dimensionality Reduction using PCA and T-SNE","metadata":{}},{"cell_type":"code","source":"def dim_reduction(algo, X, y):\n    if(algo=='T-SNE'):\n        X_reduced = TSNE(n_components=2, random_state=42).fit_transform(X.values)\n    \n    else:\n        X_reduced = PCA(n_components=2, random_state=42).fit_transform(X.values)\n    \n    ax = plt.figure(figsize=(12,8))\n\n#     ax.suptitle('Cluster after Dimensionality Reduction using '+ algo, fontsize=14)\n\n\n    purple_patch = mpatches.Patch(color='purple', label='No Fraud')\n    yellow_patch = mpatches.Patch(color='yellow', label='Fraud')\n\n#     sns.diverging_palette(250, 20, as_cmap=True)\n    # t-SNE scatter plot\n    sns.scatterplot(X_reduced[:,0], X_reduced[:,1], c=(y == 0), \n                     label='No Fraud', linewidths=2).set_title(algo, fontsize=14)\n    sns.scatterplot(X_reduced[:,0], X_reduced[:,1], c=(y == 1), \n                     label='Fraud', linewidths=2).set_title(algo, fontsize=14)\n    \n    plt.grid()\n\n    plt.legend(handles=[purple_patch, yellow_patch])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:46.507682Z","iopub.execute_input":"2022-08-21T20:22:46.507989Z","iopub.status.idle":"2022-08-21T20:22:46.518390Z","shell.execute_reply.started":"2022-08-21T20:22:46.507961Z","shell.execute_reply":"2022-08-21T20:22:46.517266Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"X = new_df.drop('Class', axis=1)\ny = new_df['Class']\n\ndim_reduction('T-SNE', X, y)\ndim_reduction('PCA', X, y)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:46.520103Z","iopub.execute_input":"2022-08-21T20:22:46.520439Z","iopub.status.idle":"2022-08-21T20:22:50.861663Z","shell.execute_reply.started":"2022-08-21T20:22:46.520411Z","shell.execute_reply":"2022-08-21T20:22:50.860266Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Training Classifier ML algorithms on Random Undersampled Data","metadata":{}},{"cell_type":"code","source":"classifiers = {\n    \"Logisitic_Regr\": LogisticRegression(),\n    \"K-NN\": KNeighborsClassifier(),\n    \"SVM\": SVC()}\n\nX = new_df.drop('Class', axis=1)\ny = new_df['Class']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nX_train = X_train.values\nX_test = X_test.values\ny_train = y_train.values\ny_test = y_test.values\n\nfor key, classifier in classifiers.items():\n    classifier.fit(X_train, y_train)\n    training_score = cross_val_score(classifier, X_train, y_train, cv=5)\n    print(\"Classifiers: \", classifier.__class__.__name__, \n          \", training score of :\", round(training_score.mean(), 2) * 100, \"% accuracy score\")","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:50.863237Z","iopub.execute_input":"2022-08-21T20:22:50.863648Z","iopub.status.idle":"2022-08-21T20:22:51.306733Z","shell.execute_reply.started":"2022-08-21T20:22:50.863612Z","shell.execute_reply":"2022-08-21T20:22:51.305485Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Use GridSearchCV to find the best parameters.\nfrom sklearn.model_selection import GridSearchCV\n\n\n# Logistic Regression \nlog_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n\n\n\ngrid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)\ngrid_log_reg.fit(X_train, y_train)\n# We automatically get the logistic regression with the best parameters.\nlog_reg = grid_log_reg.best_estimator_\n\nknears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n\ngrid_knears = GridSearchCV(KNeighborsClassifier(), knears_params)\ngrid_knears.fit(X_train, y_train)\n# KNears best estimator\nknears_neighbors = grid_knears.best_estimator_\n\n# Support Vector Classifier\nsvc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\ngrid_svc = GridSearchCV(SVC(), svc_params)\ngrid_svc.fit(X_train, y_train)\n\n# SVC best estimator\nsvc = grid_svc.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:22:51.308131Z","iopub.execute_input":"2022-08-21T20:22:51.308518Z","iopub.status.idle":"2022-08-21T20:22:54.373356Z","shell.execute_reply.started":"2022-08-21T20:22:51.308485Z","shell.execute_reply":"2022-08-21T20:22:54.372168Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Overfitting Case\n\nlog_reg_score = cross_val_score(log_reg, X_train, y_train, cv=5)\nprint('Logistic Regression Cross Validation Score: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')\n\n\nknears_score = cross_val_score(knears_neighbors, X_train, y_train, cv=5)\nprint('Knears Neighbors Cross Validation Score', round(knears_score.mean() * 100, 2).astype(str) + '%')\n\nsvc_score = cross_val_score(svc, X_train, y_train, cv=5)\nprint('Support Vector Classifier Cross Validation Score', round(svc_score.mean() * 100, 2).astype(str) + '%')","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:30:20.143886Z","iopub.execute_input":"2022-08-21T20:30:20.144317Z","iopub.status.idle":"2022-08-21T20:30:20.436542Z","shell.execute_reply.started":"2022-08-21T20:30:20.144281Z","shell.execute_reply":"2022-08-21T20:30:20.435248Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# 4. Performing NearMiss Algorithm to deal with class imbalance","metadata":{}},{"cell_type":"code","source":"# We will undersample during cross validating\nundersample_X = full_df.drop('Class', axis=1)\nundersample_y = full_df['Class']\n\nfor train_index, test_index in sss.split(undersample_X, undersample_y):\n    print(\"Train:\", train_index, \"Test:\", test_index)\n    undersample_Xtrain, undersample_Xtest = undersample_X.iloc[train_index], undersample_X.iloc[test_index]\n    undersample_ytrain, undersample_ytest = undersample_y.iloc[train_index], undersample_y.iloc[test_index]\n    \nundersample_Xtrain = undersample_Xtrain.values\nundersample_Xtest = undersample_Xtest.values\nundersample_ytrain = undersample_ytrain.values\nundersample_ytest = undersample_ytest.values \n\nundersample_accuracy = []\nundersample_precision = []\nundersample_recall = []\nundersample_f1 = []\nundersample_auc = []\n\n# Implementing NearMiss Technique \n# Distribution of NearMiss (Just to see how it distributes the labels we won't use these variables)\nX_nearmiss, y_nearmiss = NearMiss().fit_resample(undersample_X.values, undersample_y.values)\nprint('NearMiss Label Distribution: {}'.format(Counter(y_nearmiss)))\n# Cross Validating the right way\n\nfor train, test in sss.split(undersample_Xtrain, undersample_ytrain):\n    undersample_pipeline = imbalanced_make_pipeline(NearMiss(sampling_strategy='majority'), log_reg) # SMOTE happens during Cross Validation not before..\n    undersample_model = undersample_pipeline.fit(undersample_Xtrain[train], undersample_ytrain[train])\n    undersample_prediction = undersample_model.predict(undersample_Xtrain[test])\n    \n    undersample_accuracy.append(undersample_pipeline.score(original_Xtrain[test], original_ytrain[test]))\n    undersample_precision.append(precision_score(original_ytrain[test], undersample_prediction))\n    undersample_recall.append(recall_score(original_ytrain[test], undersample_prediction))\n    undersample_f1.append(f1_score(original_ytrain[test], undersample_prediction))\n    undersample_auc.append(roc_auc_score(original_ytrain[test], undersample_prediction))","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:35:43.531233Z","iopub.execute_input":"2022-08-21T20:35:43.531673Z","iopub.status.idle":"2022-08-21T20:35:53.940943Z","shell.execute_reply.started":"2022-08-21T20:35:43.531638Z","shell.execute_reply":"2022-08-21T20:35:53.939139Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Let's Plot LogisticRegression Learning Curve\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import learning_curve\n\ndef plot_learning_curve(name, estimator, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    f,ax = plt.subplots(1,1, figsize=(10,6), sharey=True)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    # First Estimator\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"#ff9124\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"#2492ff\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"#ff9124\",\n             label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"#2492ff\",\n             label=\"Cross-validation score\")\n    ax.set_title(name + \" Learning Curve\", fontsize=14)\n    ax.set_xlabel('Training size (m)')\n    ax.set_ylabel('Score')\n    ax.grid(True)\n    ax.legend(loc=\"best\")\n    \n    return plt","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:44:53.989794Z","iopub.execute_input":"2022-08-21T20:44:53.990189Z","iopub.status.idle":"2022-08-21T20:44:54.001860Z","shell.execute_reply.started":"2022-08-21T20:44:53.990150Z","shell.execute_reply":"2022-08-21T20:44:54.000541Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)\nestimators = [log_reg, knears_neighbors, svc]\nest_names = ['Logistic Regression', 'K-Nearest Neighbors', 'Support Vector Machine']\nfor name, estimator in zip(est_names,estimators):\n    plot_learning_curve(name, estimator, X_train, y_train, (0.87, 1.01), cv=cv, n_jobs=4)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:44:54.434453Z","iopub.execute_input":"2022-08-21T20:44:54.435187Z","iopub.status.idle":"2022-08-21T20:45:03.148880Z","shell.execute_reply.started":"2022-08-21T20:44:54.435145Z","shell.execute_reply":"2022-08-21T20:45:03.147549Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame with all the scores and the classifiers names.\n\nlog_reg_pred = cross_val_predict(log_reg, X_train, y_train, cv=5,\n                             method=\"decision_function\")\n\nknears_pred = cross_val_predict(knears_neighbors, X_train, y_train, cv=5)\n\nsvc_pred = cross_val_predict(svc, X_train, y_train, cv=5,\n                             method=\"decision_function\")\n\nprint('Logistic Regression: ', roc_auc_score(y_train, log_reg_pred))\nprint('KNears Neighbors: ', roc_auc_score(y_train, knears_pred))\nprint('Support Vector Classifier: ', roc_auc_score(y_train, svc_pred))","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:47:30.412560Z","iopub.execute_input":"2022-08-21T20:47:30.413091Z","iopub.status.idle":"2022-08-21T20:47:30.713801Z","shell.execute_reply.started":"2022-08-21T20:47:30.413042Z","shell.execute_reply":"2022-08-21T20:47:30.712466Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"log_fpr, log_tpr, log_thresold = roc_curve(y_train, log_reg_pred)\nknear_fpr, knear_tpr, knear_threshold = roc_curve(y_train, knears_pred)\nsvc_fpr, svc_tpr, svc_threshold = roc_curve(y_train, svc_pred)\n\ndef graph_roc_curve_multiple(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr):\n    plt.figure(figsize=(14,6))\n    plt.title('ROC Curve \\n Top 3 Classifiers', fontsize=18)\n    plt.plot(log_fpr, log_tpr, label='Logistic Regression Classifier Score: {:.4f}'.format(roc_auc_score(y_train, log_reg_pred)))\n    plt.plot(knear_fpr, knear_tpr, label='KNears Neighbors Classifier Score: {:.4f}'.format(roc_auc_score(y_train, knears_pred)))\n    plt.plot(svc_fpr, svc_tpr, label='Support Vector Classifier Score: {:.4f}'.format(roc_auc_score(y_train, svc_pred)))\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([-0.01, 1, 0, 1])\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n    plt.annotate('Minimum ROC Score of 50% \\n (This is the minimum score to get)', xy=(0.5, 0.5), xytext=(0.6, 0.3),\n                arrowprops=dict(facecolor='#6E726D', shrink=0.05),\n                )\n    plt.legend()\n    \ngraph_roc_curve_multiple(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:48:47.385280Z","iopub.execute_input":"2022-08-21T20:48:47.386590Z","iopub.status.idle":"2022-08-21T20:48:47.704467Z","shell.execute_reply.started":"2022-08-21T20:48:47.386546Z","shell.execute_reply":"2022-08-21T20:48:47.703117Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"# 5. Performing Oversampling using SMOTE","metadata":{}},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\n\n\nprint('Length of X (train): {} | Length of y (train): {}'.format(len(original_Xtrain), len(original_ytrain)))\nprint('Length of X (test): {} | Length of y (test): {}'.format(len(original_Xtest), len(original_ytest)))\n\n# List to append the score and then find the average\naccuracy_lst = []\nprecision_lst = []\nrecall_lst = []\nf1_lst = []\nauc_lst = []\n\n# Classifier with optimal parameters\n# log_reg_sm = grid_log_reg.best_estimator_\nlog_reg_sm = LogisticRegression()\n\nrand_log_reg = RandomizedSearchCV(LogisticRegression(), log_reg_params, n_iter=4)\n\n# Implementing SMOTE Technique \n# Cross Validating the right way\n# Parameters\nlog_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\nfor train, test in sss.split(original_Xtrain, original_ytrain):\n    pipeline = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_log_reg) # SMOTE happens during Cross Validation not before..\n    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n    best_est = rand_log_reg.best_estimator_\n    prediction = best_est.predict(original_Xtrain[test])\n    \n    accuracy_lst.append(pipeline.score(original_Xtrain[test], original_ytrain[test]))\n    precision_lst.append(precision_score(original_ytrain[test], prediction))\n    recall_lst.append(recall_score(original_ytrain[test], prediction))\n    f1_lst.append(f1_score(original_ytrain[test], prediction))\n    auc_lst.append(roc_auc_score(original_ytrain[test], prediction))\n    \nprint('---' * 45)\nprint('')\nprint(\"accuracy: {}\".format(np.mean(accuracy_lst)))\nprint(\"precision: {}\".format(np.mean(precision_lst)))\nprint(\"recall: {}\".format(np.mean(recall_lst)))\nprint(\"f1: {}\".format(np.mean(f1_lst)))\nprint('---' * 45)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:49:43.854313Z","iopub.execute_input":"2022-08-21T20:49:43.854996Z","iopub.status.idle":"2022-08-21T20:53:09.523425Z","shell.execute_reply.started":"2022-08-21T20:49:43.854955Z","shell.execute_reply":"2022-08-21T20:53:09.521864Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"labels = ['No Fraud', 'Fraud']\nsmote_prediction = best_est.predict(original_Xtest)\nprint(classification_report(original_ytest, smote_prediction, target_names=labels))\n\ny_score = best_est.decision_function(original_Xtest)\n\naverage_precision = average_precision_score(original_ytest, y_score)\nprint('Average precision-recall score: {0:0.2f}'.format(average_precision))","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:54:01.083634Z","iopub.execute_input":"2022-08-21T20:54:01.084056Z","iopub.status.idle":"2022-08-21T20:54:01.265583Z","shell.execute_reply.started":"2022-08-21T20:54:01.084020Z","shell.execute_reply":"2022-08-21T20:54:01.264292Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12,6))\n\nprecision, recall, _ = precision_recall_curve(original_ytest, y_score)\n\nplt.step(recall, precision, color='r', alpha=0.2,\n         where='post')\nplt.fill_between(recall, precision, step='post', alpha=0.2,\n                 color='#F59B00')\n\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0.0, 1.05])\nplt.xlim([0.0, 1.0])\nplt.title('OverSampling Precision-Recall curve: \\n Average Precision-Recall Score ={0:0.2f}'.format(\n          average_precision), fontsize=16)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:55:26.409518Z","iopub.execute_input":"2022-08-21T20:55:26.409909Z","iopub.status.idle":"2022-08-21T20:55:26.688959Z","shell.execute_reply.started":"2022-08-21T20:55:26.409878Z","shell.execute_reply":"2022-08-21T20:55:26.687732Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# SMOTE Technique (OverSampling) After splitting and Cross Validating\nsm = SMOTE(sampling_strategy=0.6, random_state=42)\n# Xsm_train, ysm_train = sm.fit_sample(X_train, y_train)\n\n# This will be the data were we are going to \nXsm_train, ysm_train = sm.fit_resample(original_Xtrain, original_ytrain)\n\n# We Improve the score by 2% points approximately \n# Implement GridSearchCV and the other models.\n\n# Logistic Regression\nlog_reg_sm = grid_log_reg.best_estimator_\nlog_reg_sm.fit(Xsm_train, ysm_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:57:38.369914Z","iopub.execute_input":"2022-08-21T20:57:38.370303Z","iopub.status.idle":"2022-08-21T20:57:44.613280Z","shell.execute_reply.started":"2022-08-21T20:57:38.370273Z","shell.execute_reply":"2022-08-21T20:57:44.611585Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Logistic Regression fitted using SMOTE technique\ny_pred_log_reg = log_reg_sm.predict(X_test)\n\n# Other models fitted with UnderSampling\ny_pred_knear = knears_neighbors.predict(X_test)\ny_pred_svc = svc.predict(X_test)\n\nlog_reg_cf = confusion_matrix(y_test, y_pred_log_reg)\nkneighbors_cf = confusion_matrix(y_test, y_pred_knear)\nsvc_cf = confusion_matrix(y_test, y_pred_svc)\n\nfig, ax = plt.subplots(2, 2,figsize=(22,12))\n\nsns.heatmap(log_reg_cf, ax=ax[0][0], annot=True, cmap=plt.cm.copper)\nax[0, 0].set_title(\"Logistic Regression \\n Confusion Matrix\", fontsize=14)\nax[0, 0].set_xticklabels(['', ''], fontsize=14, rotation=90)\nax[0, 0].set_yticklabels(['', ''], fontsize=14, rotation=360)\n\nsns.heatmap(kneighbors_cf, ax=ax[0][1], annot=True, cmap=plt.cm.copper)\nax[0][1].set_title(\"KNearsNeighbors \\n Confusion Matrix\", fontsize=14)\nax[0][1].set_xticklabels(['', ''], fontsize=14, rotation=90)\nax[0][1].set_yticklabels(['', ''], fontsize=14, rotation=360)\n\nsns.heatmap(svc_cf, ax=ax[1][0], annot=True, cmap=plt.cm.copper)\nax[1][0].set_title(\"Suppor Vector Classifier \\n Confusion Matrix\", fontsize=14)\nax[1][0].set_xticklabels(['', ''], fontsize=14, rotation=90)\nax[1][0].set_yticklabels(['', ''], fontsize=14, rotation=360)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T21:00:21.943192Z","iopub.execute_input":"2022-08-21T21:00:21.943819Z","iopub.status.idle":"2022-08-21T21:00:22.843251Z","shell.execute_reply.started":"2022-08-21T21:00:21.943762Z","shell.execute_reply":"2022-08-21T21:00:22.841961Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n\nprint('Logistic Regression:')\nprint(classification_report(y_test, y_pred_log_reg))\n\nprint('KNears Neighbors:')\nprint(classification_report(y_test, y_pred_knear))\n\nprint('Support Vector Classifier:')\nprint(classification_report(y_test, y_pred_svc))","metadata":{"execution":{"iopub.status.busy":"2022-08-21T21:02:10.675590Z","iopub.execute_input":"2022-08-21T21:02:10.675989Z","iopub.status.idle":"2022-08-21T21:02:10.695828Z","shell.execute_reply.started":"2022-08-21T21:02:10.675958Z","shell.execute_reply":"2022-08-21T21:02:10.695004Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"# Final Score in the test set of logistic regression\nfrom sklearn.metrics import accuracy_score\n\n# Logistic Regression with Under-Sampling\ny_pred = log_reg.predict(X_test)\nundersample_score = accuracy_score(y_test, y_pred)\n\n\n\n# Logistic Regression with SMOTE Technique (Better accuracy with SMOTE t)\ny_pred_sm = best_est.predict(original_Xtest)\noversample_score = accuracy_score(original_ytest, y_pred_sm)\n\n\nd = {'Technique': ['Random UnderSampling', 'Oversampling (SMOTE)'], 'Score': [undersample_score, oversample_score]}\nfinal_df = pd.DataFrame(data=d)\n\n# Move column\nscore = final_df['Score']\nfinal_df.drop('Score', axis=1, inplace=True)\nfinal_df.insert(1, 'Score', score)\n\n# Note how high is accuracy score it can be misleading! \nfinal_df","metadata":{"execution":{"iopub.status.busy":"2022-08-21T21:02:46.740810Z","iopub.execute_input":"2022-08-21T21:02:46.742466Z","iopub.status.idle":"2022-08-21T21:02:46.892784Z","shell.execute_reply.started":"2022-08-21T21:02:46.742410Z","shell.execute_reply":"2022-08-21T21:02:46.891461Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"# 9. Testing the Models","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}